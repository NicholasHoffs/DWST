{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nicho\\Desktop\\DWST\\venv\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\nicho\\Desktop\\DWST\\venv\\lib\\site-packages\\nnAudio\\Spectrogram.py:4: Warning: importing Spectrogram subpackage will be deprecated soon. You should import the feature extractor from the feature subpackage. See actual documentation.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "from librosa import load\n",
    "from IPython.display import Audio\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "from loudness_encoder import loudness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal, sr = load('../test_audio/mallet_acoustic_074-072-050.wav', sr=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STFT kernels created, time used = 0.1426 seconds\n",
      "(126,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nicho\\Desktop\\DWST\\venv\\lib\\site-packages\\librosa\\core\\convert.py:1332: RuntimeWarning: divide by zero encountered in log10\n",
      "  + 2 * np.log10(f_sq)\n"
     ]
    }
   ],
   "source": [
    "loud = loudness(signal, sr, 2048, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.4887616  -0.58308418 -0.39396979 -0.45514023 -0.58665327 -0.65151496\n",
      " -0.41690711 -1.22961666 -0.41956824 -1.02977161 -0.44759753 -0.66307724\n",
      " -0.56913343 -0.50522737 -0.82777359 -0.4460946  -1.2955806  -0.47380767\n",
      " -0.76152581 -0.58488273 -0.58133672 -0.80701388 -0.51274574 -1.42136538\n",
      " -0.51714672 -0.89398709 -0.59661722 -0.66038709 -0.77580988 -0.56904612\n",
      " -1.19644779 -0.55554615 -1.02969291 -0.61489233 -0.74571382 -0.76319375\n",
      " -0.62703795 -1.08836152 -0.59591267 -1.18771657 -0.63759795 -0.83017624\n",
      " -0.75991796 -0.68760944 -1.01468065 -0.64020672 -1.39181777 -0.6624413\n",
      " -0.92419579 -0.75968384 -0.7520357  -0.96827097 -0.68503899 -1.49697244\n",
      " -0.69196162 -1.0312727  -0.76913331 -0.82300862 -0.93840685 -0.73682199\n",
      " -1.31834723 -0.72521266 -1.1477018  -0.78514942 -0.89525806 -0.92693363\n",
      " -0.79006222 -1.22388237 -0.763981   -1.28048205 -0.80586318 -0.97708306\n",
      " -0.9217946  -0.84750095 -1.16558648 -0.80595086 -1.435002   -0.82915669\n",
      " -1.06156589 -0.92526024 -0.90621594 -1.11907873 -0.8477959  -1.56249556\n",
      " -0.85650129 -1.15129656 -0.92816245 -0.96897665 -1.08906836 -0.89288044\n",
      " -1.41276487 -0.88401054 -1.25083728 -0.92903329 -1.01377102 -0.99097951\n",
      " -0.97608092 -1.19153268 -1.0919997  -1.48323143 -1.24857002 -1.39481379\n",
      " -1.42282656 -1.42337378 -1.55389593 -1.49123976 -1.58174209 -1.53279901\n",
      " -1.57195141 -1.56143498 -1.56363417 -1.58465298 -1.56904648 -1.59918627\n",
      " -1.58248843 -1.59619086 -1.59298024 -1.59588142 -1.59980935 -1.59853492\n",
      " -1.60255993 -1.60108938 -1.6026025  -1.60260079 -1.6026431  -1.6026431 ]\n"
     ]
    }
   ],
   "source": [
    "print(loud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import librosa as li\n",
    "def extract_loudness(audio, sampling_rate, block_size=None, n_fft=2048, frame_rate=None):\n",
    "    assert (block_size is None) != (frame_rate is None), \"Specify exactly one of block_size or frame_rate\"\n",
    "\n",
    "    if frame_rate is not None:\n",
    "        block_size = sampling_rate // frame_rate\n",
    "    else:\n",
    "        frame_rate = int(sampling_rate / block_size)\n",
    "\n",
    "    if sampling_rate % frame_rate != 0:\n",
    "        raise ValueError(\n",
    "            'frame_rate: {} must evenly divide sample_rate: {}.'\n",
    "            'For default frame_rate: 250Hz, suggested sample_rate: 16kHz or 48kHz'\n",
    "            .format(frame_rate, sampling_rate))\n",
    "\n",
    "    if isinstance(audio, np.ndarray):\n",
    "        audio = torch.tensor(audio)\n",
    "\n",
    "    # Temporarily a batch dimension for single examples.\n",
    "    is_1d = (len(audio.shape) == 1)\n",
    "    audio = audio[None, :] if is_1d else audio\n",
    "\n",
    "    # Take STFT.\n",
    "    overlap = 1 - block_size / n_fft\n",
    "    amplitude = torch.stft(audio, n_fft=n_fft, hop_length=block_size, center=True, pad_mode='reflect', return_complex=True).abs()\n",
    "    amplitude = amplitude[:, :, :-1]\n",
    "    \n",
    "    # Compute power.\n",
    "    power_db = amplitude_to_db(amplitude)\n",
    "\n",
    "    # Perceptual weighting.\n",
    "    frequencies = li.fft_frequencies(sr=sampling_rate, n_fft=n_fft)\n",
    "    a_weighting = li.A_weighting(frequencies)[None,:,None]\n",
    "    loudness = power_db + a_weighting\n",
    "\n",
    "    loudness = torch.mean(torch.pow(10, loudness / 10.0), axis=1)\n",
    "    loudness = 10.0 * torch.log10(torch.clamp(loudness, min=1e-20))\n",
    "\n",
    "    # Remove temporary batch dimension.\n",
    "    loudness = loudness[0] if is_1d else loudness\n",
    "    loudness = loudness.numpy()\n",
    "\n",
    "    return loudness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "frame_rate: 31 must evenly divide sample_rate: 16000.For default frame_rate: 250Hz, suggested sample_rate: 16kHz or 48kHz",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m extract_loudness(signal, sr, \u001b[39m512\u001b[39;49m,\u001b[39m2048\u001b[39;49m)\n",
      "Cell \u001b[1;32mIn[4], line 13\u001b[0m, in \u001b[0;36mextract_loudness\u001b[1;34m(audio, sampling_rate, block_size, n_fft, frame_rate)\u001b[0m\n\u001b[0;32m     10\u001b[0m     frame_rate \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(sampling_rate \u001b[39m/\u001b[39m block_size)\n\u001b[0;32m     12\u001b[0m \u001b[39mif\u001b[39;00m sampling_rate \u001b[39m%\u001b[39m frame_rate \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m---> 13\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m     14\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mframe_rate: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m must evenly divide sample_rate: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m     15\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mFor default frame_rate: 250Hz, suggested sample_rate: 16kHz or 48kHz\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m     16\u001b[0m         \u001b[39m.\u001b[39mformat(frame_rate, sampling_rate))\n\u001b[0;32m     18\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(audio, np\u001b[39m.\u001b[39mndarray):\n\u001b[0;32m     19\u001b[0m     audio \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(audio)\n",
      "\u001b[1;31mValueError\u001b[0m: frame_rate: 31 must evenly divide sample_rate: 16000.For default frame_rate: 250Hz, suggested sample_rate: 16kHz or 48kHz"
     ]
    }
   ],
   "source": [
    "extract_loudness(signal, sr, 512,2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cbe56aed1225ee400ffdf35c87acf515042cda23671409b3c5f637add460d823"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
